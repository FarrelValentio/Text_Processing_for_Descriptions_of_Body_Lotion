# -*- coding: utf-8 -*-
"""UTS_Farrel_6162001194

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HM7u-Z740zmVpspN5sRnutur3Js0ko9r

# <center> UTS Analisis Media Sosial

---




Nama : Farrel Valentio Halim

NPM  : 6162001194

Kelas : A

# No.1
"""

import pandas as pd
import numpy as np
df = pd.read_csv("body_lotion.csv")

"""Dataset yang dibuat berdasarkan review pembeli dari e-commerce bernama female daily. Data yang digunakan mengenai ulasan tentang kualitas produk dan pengalaman pembeli selama pemakaian produk. Kemudian, di dalamnya terdiri dari kolom No, produk, review, rating, dan sumber. Variabel yang akan dianalisis sebagai parameter di antaranya produk, review dan rating.

# No.2

Berikut ditampilkan tabel data sebanyak 20 produk dari no 1
"""

df.head(20)

"""# No.3

## Preprocessing

Preprocessing dilakukan dengan mengubah format data kolom 'review' dari dataset menjadi format string.
"""

df['review'] = df['review'].astype(str)

"""Kemudian akan menghilangkan setiap baris null pada kolom 'review'"""

df = df[~df['review'].isnull()]

"""Akan dibersihkan setiap kalimat pada kolom 'review' untuk menghindarkan kesalahan penulisan"""

def clean(txt):
    txt = txt.str.replace("()", "")
    txt = txt.str.replace('(<a).*(>).*()', '')
    txt = txt.str.replace('(&amp)', '')
    txt = txt.str.replace('(&gt)', '')
    txt = txt.str.replace('(&lt)', '')
    txt = txt.str.replace('(\xa0)', ' ')
    return txt

df['review'] = clean(df['review'])

"""Mengubah seluruh huruf dalam kalimat pada kolom 'review' menjadi huruf kecil"""

df['review1'] = df['review'].apply(lambda x: " ".join(x.lower() for x in x.split()))
df['review1'].head()

"""Menghapus tanda baca pada setiap huruf dalam kalimat"""

df['review1'] = df['review1'].str.replace('[^\w\s]', '')
df['review1'].head()

"""**Removing Stopwords**

Menghilangkan setiap kata yang kurang penting dan jarang dipakai
"""

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
stop = stopwords.words('indonesian')
df['review1'] = df['review1'].apply(lambda x: " ".join(x for x in x.split() if x not in stop))
df['review1'].head()

"""**Remove the Rare Words**

Menghapus setiap kata yang jarang dipakai atau frekuensi penggunaanya rendah seperti hanya satu kali muncul.
"""

# frekuensi kata kata yang sering muncul
freq = pd.Series(' '.join(df['review1']).split()).value_counts()
less_freq = list(freq[freq ==1].index)
less_freq

"""**Spelling Correction**

Menyederhanakan kesalahan pengejaan setiap kata.
"""

from textblob import TextBlob, Word, Blobber
df['review1'].apply(lambda x: str(TextBlob(x).correct()))
df['review1'].head()

"""**Stemming and Lemmatization**

Mengubah setiap kata menjadi kata dasar.
"""

# proses preprocessing menggunakan dataset yang banyak jadi lama
from nltk.stem import PorterStemmer
st = PorterStemmer()
df['review1'] = df['review'].apply(lambda x: " ".join([st.stem(word) for word in x.split()]))

"""Sekarang akan dihapus setiap tanda baca yang ada."""

df['review1'] = df['review1'].str.replace('[^\w\s]', '')
df['review1'].head()

"""## Data Analysis

Dibuat dua buah variabel yang menunjukkan jumlah kata dalam setiap review dan banyaknya review.
"""

df['review_len'] = df['review'].astype(str).apply(len)
df['word_count'] = df['review'].apply(lambda x: len(str(x).split()))

"""Kemudian, ditambahkan juga variabel polarity untuk mengukur tingkat sentimen user berdasarkan review terhadap produk yang ada. Range value polarity antara -1 sampai 1. Jika polarity semakin bernilai negatif, menunjukkan sentimen review tersebut negatif juga. Jika polarity semakin bernilai positif, menunjukkan sentimen review positif juga. Jika polarity bernilai 0, maka sentimen review bersifat netral."""

df['polarity'] = df['review1'].map(lambda text: TextBlob(text).sentiment.polarity)
df.head()

"""Akan dicari distribusi antara review_len, word_count, dan polarity."""

df[["review_len", "word_count", "polarity"]].hist(bins=20, figsize=(15,10))

"""Terlihat distribusi review_len dan word_count hampir sama. Terlihat juga, sebagian besar polarity bernilai 0 menunjukkan paling banyak review bersifat netral.

**Polarity vs Rating**

Boxplot polarity berdasarkan rating
"""

import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize = (10, 8))
sns.set_style('whitegrid')
sns.set(font_scale = 1.5)
sns.boxplot(x='rating',y='polarity',data=df)
plt.xlabel("Rating")
plt.ylabel("Polarity")
plt.title("Product Ratings vs Polarity")
plt.show()

mean_pol = df.groupby('rating')['polarity'].agg([np.mean])
mean_pol.columns = ['mean_polarity']
fig, ax = plt.subplots(figsize=(8, 6))
plt.bar(mean_pol.index, mean_pol.mean_polarity, width=0.3)
#plt.gca().set_xticklabels(mean_pol.index, fontdict={'size': 14})
for i in ax.patches:
    ax.text(i.get_x(), i.get_height()+0.01, str("{:.2f}".format(i.get_height())))

plt.title("Polarity of Ratings", fontsize=22)
plt.ylabel("Polarity", fontsize=16)
plt.xlabel("Rating", fontsize=16)
plt.ylim(0, 0.35)
plt.show()

"""**Count of the Reviews for Each Rating**

Akan dicari jumlah review pada masing - masing rating.
"""

plt.figure(figsize=(8, 6))
sns.countplot(x='rating', data=df)
plt.xlabel("Rating")
plt.title("Number of data of each rating")
plt.show()

plt.figure(figsize=(10, 6))
sns.pointplot(x='rating',y='review_len',data=df)
plt.xlabel("Rating")
plt.ylabel("Review Length")
plt.title("Product Rating vs Review Length")
plt.show()

"""Berdasarkan grafik di atas, menunjukkan rating 1 dan rating 5 memiliki jumlah kata pada review yang lebih sedikit. Yang artinya, pembeli yang suka maupun tidak suka dengan produknya cenderung tidak banyak mengekspresikannya dalam kalimat pada review.

**Top 20 products based on the Polarity**

Ditampilkan 20 produk berdasarkan polarity.
"""

product_pol = df.groupby('produk')['polarity'].agg([np.mean])
product_pol.columns = ['polarity']
product_pol = product_pol.sort_values('polarity', ascending=False)
product_pol = product_pol.head(20)
product_pol

"""# No.4

Menginstall package wordcloud untuk menampilkan data teks ke dalam bentuk visual sehingga user mudah untuk memahaminya.
"""

!pip install wordcloud

"""Kemudian untuk mencari semua komentar menggunakan wordcloud, maka akan diambil kolom rating, untuk mengambil semua review dari rating 1 sampai 5."""

df_positive = df.loc[df['rating']>0]
text = " ".join(review for review in df_positive.review)

from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
stopwords = set(STOPWORDS)
stopwords = stopwords.union(["ha", "thi", "now", "onli", "im", "becaus", "wa", "will", "even", "go", "realli", "didnt", "abl"])
wordcl = WordCloud(stopwords = stopwords, background_color='#E0E0EE', max_font_size = 50, max_words = 5000).generate(text)
plt.figure(figsize=(14, 12))
plt.imshow(wordcl, interpolation='bilinear')
plt.axis('off')
plt.show()

"""Akan dicari frekuensi kata yang paling muncul dari semua review dan akan diambil sebanyak 20 kata dengan frekuensi tertinggi."""

from sklearn.feature_extraction.text import CountVectorizer

def get_top_n_words(corpus, n=None):
    vec=CountVectorizer().fit(corpus)
    bag_of_words = vec.transform(corpus)
    sum_words = bag_of_words.sum(axis=0)
    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]
    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)
    return words_freq[:n]

common_words = get_top_n_words(df['review1'], 20)
df1 = pd.DataFrame(common_words, columns = ['Review', 'count'])
df1.head()

df1.groupby('Review').sum()['count'].sort_values(ascending=False).plot(
    kind='bar',
    figsize=(10, 6),
    xlabel = "Top Words",
    ylabel = "Count",
    title = "Bar Chart of Top Words Frequency"
)

"""# No.5

Kemudian untuk mencari semua komentar dengan rating 3 ke bawah menggunakan wordcloud, maka akan diambil dengan slicing kolom rating dengan rating 3 ke bawah, yang artinya bahwa produk tersebut kurang bagus.
"""

df_rating = df.loc[df['rating']<=3]
text1 = " ".join(review for review in df_rating.review)

from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
stopwords = set(STOPWORDS)
stopwords = stopwords.union(["ha", "thi", "now", "onli", "im", "becaus", "wa", "will", "even", "go", "realli", "didnt", "abl"])
wordcl = WordCloud(stopwords = stopwords, background_color='#B4B4EE', max_font_size = 50, max_words = 5000).generate(text1)
plt.figure(figsize=(14, 12))
plt.imshow(wordcl, interpolation='bilinear')
plt.axis('off')
plt.show()

"""Berdasarkan visual yang ditampilkan, terlihat kata - kata yang paling banyak digunakan untuk mereview produk dengan rating 3 ke bawah, diantaranya aku, tapi, jadi, banget, gak, ga, kering, ada, bikin, ini, dan, pake, yang, karena.

# No.6

Kemudian untuk mencari semua komentar dengan rating 4 ke atas menggunakan wordcloud, maka akan diambil dengan slicing kolom rating dengan rating 4 ke atas, yang artinya bahwa produk tersebut sangat bagus.
"""

df_rating2 = df.loc[df['rating']>=4]

text2 = " ".join(review for review in df_rating2.review)

from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
stopwords = set(STOPWORDS)
stopwords = stopwords.union(["ha", "thi", "now", "onli", "im", "becaus", "wa", "will", "even", "go", "realli", "didnt", "abl"])
wordcl = WordCloud(stopwords = stopwords, background_color='#F8F8F8', max_font_size = 50, max_words = 5000).generate(text2)
plt.figure(figsize=(14, 12))
plt.imshow(wordcl, interpolation='bilinear')
plt.axis('off')
plt.show()

"""Berdasarkan visual yang ditampilkan, terlihat kata - kata yang paling banyak digunakan user untuk mereview produk dengan rating 4 ke atas, diantaranya aku, dan, yang, juga, ini, wanginya, ada, kulit, wanginya, banget, lotion, banget."""